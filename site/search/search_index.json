{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Agentic System","text":"<p>Welcome to the Agentic System documentation \u2013 your comprehensive guide to our multi-agent framework for energy sector analysis, calculations, and reporting.</p>"},{"location":"#overview","title":"Overview","text":"<p>The Agentic System is a powerful framework built with AutoGen and modern AI techniques to solve complex problems in the energy sector. It orchestrates multiple specialized agents to handle tasks including:</p> <ul> <li>Energy calculations (LCOE, capacity factors, NPV)</li> <li>Data retrieval and processing</li> <li>Formula resolution and validation</li> <li>Quality control and reporting</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multi-Agent Architecture: Specialized agents working together to solve complex problems</li> <li>Flexible Data Integration: Connect to databases, APIs, and local files</li> <li>Quality Assurance: Built-in validation and auditing of results</li> <li>Extensible Framework: Easy to customize and add new capabilities</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>New to Agentic System? Start here:</p> <ul> <li>Introduction - Learn about the system's architecture and capabilities</li> <li>Installation - Set up your environment</li> <li>Quickstart - Run your first analysis in 15 minutes</li> </ul>"},{"location":"#documentation-sections","title":"Documentation Sections","text":"<ul> <li>Getting Started: Onboarding guides for new users</li> <li>Configuration: Detailed configuration options</li> <li>Troubleshooting: Solutions for common issues</li> </ul>"},{"location":"#system-architecture","title":"System Architecture","text":"<pre><code>graph TD\n    A[User Query] --&gt; B[Task Manager]\n    B --&gt; C[Parameter Extraction]\n    B --&gt; D[Formula Resolution]\n    B --&gt; E[Data Retrieval]\n    C &amp; D &amp; E --&gt; F[Calculation Execution]\n    F --&gt; G[Quality Auditing]\n    G --&gt; H[Result Formatting]\n    H --&gt; I[Final Response]</code></pre>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"self_healing_queries/","title":"Self-Healing Query System","text":"<p>The Self-Healing Query System is a sophisticated feature of the PostgresDataProvider agent that enables robust and resilient data retrieval even when initial queries fail.</p>"},{"location":"self_healing_queries/#overview","title":"Overview","text":"<p>In real-world scenarios, data retrieval often faces challenges:</p> <ul> <li>Requested data might not exist for specific time periods</li> <li>Geographic regions may have incomplete data coverage</li> <li>Data may be stored with different naming conventions</li> <li>API endpoints might have temporary availability issues</li> </ul> <p>The Self-Healing Query System addresses these challenges by automatically generating fallback queries with progressively relaxed constraints until usable data is found.</p>"},{"location":"self_healing_queries/#key-concepts","title":"Key Concepts","text":""},{"location":"self_healing_queries/#progressive-constraint-relaxation","title":"Progressive Constraint Relaxation","text":"<p>When an initial query fails, the system applies intelligent relaxation strategies:</p> <ol> <li>Time Constraint Relaxation: Expanding date ranges or shifting time periods</li> <li>Geographic Scope Expansion: Widening the geographic area (city \u2192 state \u2192 country)</li> <li>Energy Metric Simplification: Falling back to related or proxy metrics</li> <li>General Constraint Removal: Removing non-essential filters</li> </ol>"},{"location":"self_healing_queries/#intelligent-fallback-generation","title":"Intelligent Fallback Generation","text":"<p>The system uses LLMs to analyze the original query and generate appropriate fallbacks:</p> <pre><code>async def generate_fallback_query(self, original_query, failed_attempts, strategy):\n    \"\"\"Generate a fallback query using a specific relaxation strategy\"\"\"\n    prompt = f\"\"\"\n    Original query: {original_query}\n    Failed attempts: {failed_attempts}\n\n    Generate a new PostgreSQL query using the '{strategy}' relaxation strategy.\n    Explain your changes in a comment at the beginning of the query.\n    \"\"\"\n\n    response = await self.llm_provider.get_completion(prompt)\n    return self._extract_query_from_response(response)\n</code></pre>"},{"location":"self_healing_queries/#metadata-tracking","title":"Metadata Tracking","text":"<p>Each query attempt is tracked with detailed metadata:</p> <pre><code>{\n  \"original_query\": \"SELECT avg(capacity_factor) FROM wind_plants WHERE region='Texas' AND date BETWEEN '2022-01-01' AND '2022-12-31'\",\n  \"attempts\": [\n    {\n      \"query\": \"SELECT avg(capacity_factor) FROM wind_plants WHERE region='Texas' AND date BETWEEN '2022-01-01' AND '2022-12-31'\",\n      \"strategy\": \"original\",\n      \"success\": false,\n      \"error\": \"No data available for specified period\",\n      \"timestamp\": \"2023-05-01T12:34:56Z\"\n    },\n    {\n      \"query\": \"SELECT avg(capacity_factor) FROM wind_plants WHERE region='Texas' AND date BETWEEN '2021-01-01' AND '2022-12-31'\",\n      \"strategy\": \"time_relaxation\",\n      \"success\": true,\n      \"rows_returned\": 12,\n      \"timestamp\": \"2023-05-01T12:34:58Z\"\n    }\n  ],\n  \"final_success\": true,\n  \"processing_time_ms\": 2345,\n  \"relaxation_steps\": 1\n}\n</code></pre>"},{"location":"self_healing_queries/#implementation","title":"Implementation","text":""},{"location":"self_healing_queries/#core-components","title":"Core Components","text":"<p>The Self-Healing Query System consists of three main components:</p> <ol> <li>Query Analyzer: Parses and understands the structure and constraints of the original query</li> <li>Strategy Selector: Determines which relaxation strategy to apply based on query context</li> <li>Fallback Generator: Creates new queries with relaxed constraints</li> </ol>"},{"location":"self_healing_queries/#code-structure","title":"Code Structure","text":"<p>The primary implementation is in the <code>PostgresDataProvider</code> class:</p> <pre><code>async def execute_query(self, query: str, allow_self_healing=True, max_fallback_attempts=3):\n    \"\"\"Execute a query with self-healing capabilities\"\"\"\n    # Initial query attempt\n    result = await self._execute_raw_query(query)\n\n    # Return if successful or self-healing is disabled\n    if result[\"success\"] or not allow_self_healing:\n        return result\n\n    # Prepare for fallback attempts\n    attempts = [{\"query\": query, \"strategy\": \"original\", \"success\": False, \"error\": result[\"error\"]}]\n\n    # Try fallback strategies\n    for attempt in range(max_fallback_attempts):\n        strategy = self._select_relaxation_strategy(query, attempts)\n        fallback_query = await self._generate_fallback_query(query, attempts, strategy)\n\n        fallback_result = await self._execute_raw_query(fallback_query)\n        attempts.append({\n            \"query\": fallback_query,\n            \"strategy\": strategy,\n            \"success\": fallback_result[\"success\"],\n            \"error\": fallback_result.get(\"error\"),\n            \"rows_returned\": len(fallback_result.get(\"data\", [])) if fallback_result[\"success\"] else 0\n        })\n\n        # Return on successful fallback\n        if fallback_result[\"success\"]:\n            return {\n                \"success\": True,\n                \"data\": fallback_result[\"data\"],\n                \"self_healing\": {\n                    \"original_query\": query,\n                    \"attempts\": attempts,\n                    \"final_success\": True,\n                    \"relaxation_steps\": attempt + 1\n                }\n            }\n\n    # Return failure after all attempts\n    return {\n        \"success\": False,\n        \"error\": \"Failed to retrieve data after multiple fallback attempts\",\n        \"self_healing\": {\n            \"original_query\": query,\n            \"attempts\": attempts,\n            \"final_success\": False,\n            \"relaxation_steps\": max_fallback_attempts\n        }\n    }\n</code></pre>"},{"location":"self_healing_queries/#relaxation-strategies","title":"Relaxation Strategies","text":""},{"location":"self_healing_queries/#time-relaxation","title":"Time Relaxation","text":"<p>Expands time windows to capture more data:</p> <ul> <li>Expanding day ranges (\u00b17 days)</li> <li>Expanding month ranges (\u00b11-3 months)</li> <li>Shifting to previous years for seasonal data</li> <li>Using year-to-date or trailing twelve months</li> </ul>"},{"location":"self_healing_queries/#geographic-expansion","title":"Geographic Expansion","text":"<p>Progressively widens geographic scope:</p> <ul> <li>City \u2192 County \u2192 State \u2192 Region \u2192 Country \u2192 Global</li> <li>Including nearby or similar geographic areas</li> <li>Aggregating across multiple regions</li> </ul>"},{"location":"self_healing_queries/#metric-simplification","title":"Metric Simplification","text":"<p>Falls back to related or proxy metrics:</p> <ul> <li>Capacity factor \u2192 Availability factor</li> <li>Hourly data \u2192 Daily averages</li> <li>Specific plant data \u2192 Plant type averages</li> <li>Measured data \u2192 Modeled/estimated data</li> </ul>"},{"location":"self_healing_queries/#general-relaxation","title":"General Relaxation","text":"<p>Removes non-essential filters:</p> <ul> <li>Removing specific technology filters</li> <li>Generalizing plant classifications</li> <li>Reducing precision requirements</li> <li>Removing secondary constraints</li> </ul>"},{"location":"self_healing_queries/#configuration","title":"Configuration","text":"<p>The Self-Healing Query System can be configured through settings:</p> <pre><code>{\n  \"self_healing\": {\n    \"enabled\": true,\n    \"max_fallback_attempts\": 3,\n    \"strategies\": [\"time_relaxation\", \"geography_expansion\", \"metric_simplification\", \"general_relaxation\"],\n    \"prioritize_strategies_by_query_type\": true,\n    \"relaxation_factors\": {\n      \"time\": {\n        \"day_expansion\": 7,\n        \"month_expansion\": 1,\n        \"year_expansion\": 1\n      },\n      \"geography\": [\"state\", \"region\", \"country\", \"global\"]\n    },\n    \"return_all_attempts\": true\n  }\n}\n</code></pre>"},{"location":"self_healing_queries/#usage-examples","title":"Usage Examples","text":""},{"location":"self_healing_queries/#basic-usage","title":"Basic Usage","text":"<pre><code># With self-healing enabled (default)\nresult = await postgres_provider.execute_query(\n    \"SELECT avg(capacity_factor) FROM wind_plants WHERE region='Texas' AND date BETWEEN '2022-01-01' AND '2022-12-31'\"\n)\n\n# Disable self-healing for strict queries\nresult = await postgres_provider.execute_query(\n    \"SELECT revenue FROM financial_data WHERE project_id=123\",\n    allow_self_healing=False\n)\n</code></pre>"},{"location":"self_healing_queries/#custom-fallback-attempts","title":"Custom Fallback Attempts","text":"<pre><code># Increase fallback attempts for important queries\nresult = await postgres_provider.execute_query(\n    \"SELECT hourly_price FROM electricity_market WHERE region='CAISO' AND date='2023-01-15'\",\n    max_fallback_attempts=5\n)\n</code></pre>"},{"location":"self_healing_queries/#accessing-self-healing-metadata","title":"Accessing Self-Healing Metadata","text":"<pre><code>result = await postgres_provider.execute_query(query)\nif result[\"success\"]:\n    data = result[\"data\"]\n\n    # Check if self-healing was activated\n    if \"self_healing\" in result:\n        original_query = result[\"self_healing\"][\"original_query\"]\n        attempts = result[\"self_healing\"][\"attempts\"]\n        relaxation_steps = result[\"self_healing\"][\"relaxation_steps\"]\n\n        print(f\"Data retrieved after {relaxation_steps} relaxation steps\")\n\n        # Show the successful strategy\n        successful_attempt = next(a for a in attempts if a[\"success\"])\n        print(f\"Successful strategy: {successful_attempt['strategy']}\")\n</code></pre>"},{"location":"self_healing_queries/#best-practices","title":"Best Practices","text":"<ol> <li>Set appropriate max_fallback_attempts: Balance between thoroughness and performance</li> <li>Consider query importance: Disable self-healing for critical financial or regulatory data where approximations are not acceptable</li> <li>Monitor and analyze fallback patterns: Use the metadata to identify common data gaps</li> <li>Customize relaxation strategies: Tailor strategies to your specific data domains</li> </ol>"},{"location":"self_healing_queries/#limitations","title":"Limitations","text":"<ul> <li>Not suitable for exact-match requirements (e.g., financial transactions)</li> <li>May return less specific data than originally requested</li> <li>Requires careful validation of relaxed results</li> <li>Additional processing time due to multiple query attempts</li> </ul>"},{"location":"assets/","title":"Assets Directory","text":"<p>This directory contains visual assets for the Agentic System documentation.</p>"},{"location":"assets/#logo","title":"Logo","text":"<p>The logo (<code>logo.png</code>) represents a stylized AI agent with network connections, symbolizing:</p> <ul> <li>The intelligent agent-based architecture of the system</li> <li>The interconnected nature of the specialized agents</li> <li>The data flow between components</li> <li>The robotic/AI foundation of the system</li> </ul>"},{"location":"assets/#favicon","title":"Favicon","text":"<p>The favicon (<code>favicon.png</code>) is a simplified version of the logo, designed for browser tabs and bookmarks.</p>"},{"location":"assets/#other-assets","title":"Other Assets","text":"<p>Additional images and diagrams used throughout the documentation are stored in this directory.</p>"},{"location":"configuration/","title":"Configuration Overview","text":"<p>This section covers the various configuration options available in the Agentic System. Proper configuration is essential for optimal performance and integration with your specific environment.</p>"},{"location":"configuration/#configuration-methods","title":"Configuration Methods","text":"<p>The Agentic System supports multiple configuration methods, with the following precedence order (highest to lowest):</p> <ol> <li>Environment variables</li> <li><code>.env</code> file</li> <li>Configuration files in the <code>config/</code> directory</li> <li>Default values</li> </ol>"},{"location":"configuration/#core-configuration-files","title":"Core Configuration Files","text":""},{"location":"configuration/#configsettingspy","title":"<code>config/settings.py</code>","text":"<p>Contains the central configuration logic and default values for the entire system:</p> <pre><code># Example settings.py structure\nfrom pathlib import Path\nimport os\nimport json\n\nBASE_DIR = Path(__file__).resolve().parent.parent\nDATA_DIR = BASE_DIR / \"data\"\nLOGS_DIR = BASE_DIR / \"logs\"\n\n# Load settings from environment variables or default values\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\nOPENAI_API_BASE = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\nOPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4\")\n</code></pre>"},{"location":"configuration/#configllm_settingsjson","title":"<code>config/llm_settings.json</code>","text":"<p>JSON configuration file for LLM-specific settings:</p> <pre><code>{\n  \"default_model\": \"gpt-4\",\n  \"temperature\": 0.1,\n  \"max_tokens\": 4000,\n  \"models\": {\n    \"gpt-4\": {\n      \"system_message\": \"You are an expert energy analyst assistant...\"\n    },\n    \"gpt-3.5-turbo\": {\n      \"system_message\": \"You are a helpful energy assistant...\"\n    }\n  }\n}\n</code></pre>"},{"location":"configuration/#configpostgres_settingsjson","title":"<code>config/postgres_settings.json</code>","text":"<p>Configuration for PostgreSQL database connections:</p> <pre><code>{\n  \"host\": \"localhost\",\n  \"port\": 5432,\n  \"database\": \"energy_data\",\n  \"user\": \"postgres\",\n  \"password\": \"\",\n  \"ssl_mode\": \"prefer\",\n  \"timeout\": 30\n}\n</code></pre>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":"<p>Key environment variables that can be set:</p> Variable Description Default <code>OPENAI_API_KEY</code> OpenAI API key Required <code>OPENAI_API_BASE</code> OpenAI API base URL https://api.openai.com/v1 <code>OPENAI_MODEL</code> OpenAI model to use gpt-4 <code>OPENAI_EMBEDDING_MODEL</code> Embedding model text-embedding-ada-002 <code>DATABASE_URL</code> SQL database URL sqlite:///./data.db <code>VECTOR_DB_PATH</code> Vector database path ./vector_db <code>PLEXOS_DB_PATH</code> Plexos database path \"\" <code>LOG_LEVEL</code> Logging level INFO <code>MAX_RETRIES</code> Max API retries 3 <code>TIMEOUT</code> Request timeout 30"},{"location":"configuration/#agent-specific-configuration","title":"Agent-Specific Configuration","text":"<p>Each agent has its own configuration parameters that can be adjusted:</p> <ul> <li>LLM Settings - Configuration for language models</li> <li>Database Settings - Database connection parameters</li> <li>Calculation Settings - Parameters for the calculation engine</li> <li>Logging Settings - Log levels and formatting options</li> </ul>"},{"location":"configuration/#configuration-helper","title":"Configuration Helper","text":"<p>The system includes a <code>config_helper.py</code> utility for simplified configuration management:</p> <pre><code>from config_helper import get_config\n\n# Load specific configuration\npostgres_config = get_config(\"postgres\")\nopenai_config = get_config(\"openai\")\n\n# Access configuration values\ndatabase_name = postgres_config[\"database\"]\napi_key = openai_config[\"api_key\"]\n</code></pre>"},{"location":"configuration/#advanced-configuration","title":"Advanced Configuration","text":"<p>For advanced users, the system supports:</p> <ul> <li>Dynamic configuration: Updating configuration at runtime</li> <li>Profile-based configuration: Loading different settings for development, testing, and production</li> <li>Encrypted secrets: Storing sensitive configuration values securely</li> </ul> <p>See the Advanced Configuration page for more details.</p>"},{"location":"configuration/database/","title":"Database Configuration","text":"<p>This document covers the configuration options for database connections in the Agentic System.</p>"},{"location":"configuration/database/#overview","title":"Overview","text":"<p>The Agentic System uses multiple database technologies to handle different types of data:</p> <ol> <li>Relational Databases (PostgreSQL/SQLite): For structured data storage</li> <li>Vector Databases: For semantic search and embedding storage</li> <li>File-Based Storage: For CSV files and raw data</li> </ol>"},{"location":"configuration/database/#postgresql-configuration","title":"PostgreSQL Configuration","text":"<p>PostgreSQL is used for structured data queries, especially through the PostgresDataProvider agent. Configuration is stored in <code>config/postgres_settings.json</code>.</p>"},{"location":"configuration/database/#basic-configuration","title":"Basic Configuration","text":"<pre><code>{\n  \"host\": \"localhost\",\n  \"port\": 5432,\n  \"database\": \"energy_data\",\n  \"user\": \"postgres\",\n  \"password\": \"\",\n  \"ssl_mode\": \"prefer\",\n  \"timeout\": 30,\n  \"connection_pool\": {\n    \"min_size\": 1,\n    \"max_size\": 10\n  },\n  \"application_name\": \"agentic_system\"\n}\n</code></pre>"},{"location":"configuration/database/#docker-configuration","title":"Docker Configuration","text":"<p>A separate configuration file <code>postgres_settings.docker.json</code> is provided for Docker environments:</p> <pre><code>{\n  \"host\": \"postgres\",\n  \"port\": 5432,\n  \"database\": \"energy_data\",\n  \"user\": \"postgres\",\n  \"password\": \"postgres\",\n  \"ssl_mode\": \"disable\"\n}\n</code></pre>"},{"location":"configuration/database/#environment-variables","title":"Environment Variables","text":"<p>PostgreSQL settings can be overridden with environment variables:</p> Variable Description Maps To <code>POSTGRES_HOST</code> Database host <code>host</code> <code>POSTGRES_PORT</code> Database port <code>port</code> <code>POSTGRES_DB</code> Database name <code>database</code> <code>POSTGRES_USER</code> Username <code>user</code> <code>POSTGRES_PASSWORD</code> Password <code>password</code> <code>POSTGRES_SSL_MODE</code> SSL mode <code>ssl_mode</code>"},{"location":"configuration/database/#connection-string","title":"Connection String","text":"<p>Alternatively, the entire connection can be specified via the <code>DATABASE_URL</code> environment variable:</p> <pre><code>DATABASE_URL=postgresql://username:password@localhost:5432/energy_data\n</code></pre>"},{"location":"configuration/database/#vector-database-configuration","title":"Vector Database Configuration","text":"<p>The system uses a vector database for semantic search. Configuration is typically in environment variables:</p> <pre><code>VECTOR_DB_PATH=./data/vector_db\nVECTOR_DB_TYPE=chromadb\n</code></pre>"},{"location":"configuration/database/#chromadb-configuration","title":"ChromaDB Configuration","text":"<p>For ChromaDB-specific settings:</p> <pre><code>{\n  \"persist_directory\": \"./data/vector_db\",\n  \"collection_name\": \"energy_documents\",\n  \"embedding_function\": \"openai\",\n  \"metadata_fields\": [\"source\", \"date\", \"author\", \"category\"]\n}\n</code></pre>"},{"location":"configuration/database/#custom-vector-database-settings","title":"Custom Vector Database Settings","text":"<p>For advanced vector database configurations:</p> <pre><code>\"vector_db\": {\n  \"provider\": \"chromadb\",\n  \"settings\": {\n    \"persist_directory\": \"./data/vector_db\",\n    \"collection_name\": \"energy_documents\"\n  },\n  \"embedding\": {\n    \"model\": \"text-embedding-ada-002\",\n    \"dimensions\": 1536,\n    \"batch_size\": 100\n  }\n}\n</code></pre>"},{"location":"configuration/database/#sqlite-configuration","title":"SQLite Configuration","text":"<p>For simpler deployments, SQLite is used as a lightweight database:</p> <pre><code>DATABASE_URL=sqlite:///./data.db\n</code></pre> <p>Additional SQLite configuration:</p> <pre><code>\"sqlite\": {\n  \"filename\": \"./data.db\",\n  \"journal_mode\": \"WAL\",\n  \"synchronous\": \"NORMAL\",\n  \"foreign_keys\": true,\n  \"timeout\": 30\n}\n</code></pre>"},{"location":"configuration/database/#self-healing-query-configuration","title":"Self-Healing Query Configuration","text":"<p>Configuration for the self-healing query system used by the PostgresDataProvider:</p> <pre><code>\"self_healing\": {\n  \"enabled\": true,\n  \"max_fallback_attempts\": 3,\n  \"strategies\": [\"time_relaxation\", \"geography_expansion\", \"metric_simplification\", \"general_relaxation\"],\n  \"relaxation_factors\": {\n    \"time\": {\n      \"day_expansion\": 7,\n      \"month_expansion\": 1,\n      \"year_expansion\": 1\n    },\n    \"geography\": [\"state\", \"region\", \"country\", \"global\"]\n  }\n}\n</code></pre>"},{"location":"configuration/database/#connection-pooling","title":"Connection Pooling","text":"<p>For high-performance applications, connection pooling is configured:</p> <pre><code>\"connection_pool\": {\n  \"min_size\": 5,\n  \"max_size\": 20,\n  \"max_idle\": 300,\n  \"max_queries\": 50000,\n  \"setup\": [\"SET application_name TO 'agentic_system'\"]\n}\n</code></pre>"},{"location":"configuration/database/#security-best-practices","title":"Security Best Practices","text":"<ul> <li>Store passwords and sensitive information in environment variables, not in config files</li> <li>Use connection string URLs with limited user privileges</li> <li>Enable SSL for all production connections</li> <li>Implement connection timeouts to prevent resource exhaustion</li> </ul>"},{"location":"configuration/database/#troubleshooting","title":"Troubleshooting","text":"<p>Common database configuration issues:</p> Issue Solution Connection refused Check host, port, and firewall settings Authentication failed Verify username and password Database not found Confirm database name and create if necessary Connection pool exhaustion Increase <code>max_size</code> or check for connection leaks Timeout errors Adjust <code>timeout</code> setting or check query performance"},{"location":"configuration/llm/","title":"LLM Configuration","text":"<p>This document details the configuration options for language models in the Agentic System.</p>"},{"location":"configuration/llm/#overview","title":"Overview","text":"<p>The Agentic System relies heavily on Large Language Models (LLMs) for natural language understanding, code generation, formula creation, and other tasks. Configuring these models properly is essential for system performance and cost management.</p>"},{"location":"configuration/llm/#configuration-file","title":"Configuration File","text":"<p>LLM settings are primarily stored in <code>config/llm_settings.json</code>. This file contains model selections, parameters, and prompt templates.</p>"},{"location":"configuration/llm/#sample-configuration","title":"Sample Configuration","text":"<pre><code>{\n  \"default_model\": \"gpt-4\",\n  \"temperature\": 0.1,\n  \"max_tokens\": 4000,\n  \"request_timeout\": 60,\n  \"retry_count\": 3,\n  \"backoff_factor\": 2,\n  \"models\": {\n    \"gpt-4\": {\n      \"system_message\": \"You are an expert energy analyst assistant specialized in energy calculations and data analysis. You have deep knowledge of energy economics, renewable energy systems, and power markets. You can perform detailed calculations including LCOE, NPV, IRR, capacity factors, and other energy-related metrics.\",\n      \"temperature\": 0.1,\n      \"max_tokens\": 4000\n    },\n    \"gpt-3.5-turbo\": {\n      \"system_message\": \"You are a helpful energy assistant that can perform calculations and answer questions about energy systems.\",\n      \"temperature\": 0.2,\n      \"max_tokens\": 2048\n    }\n  },\n  \"embedding_model\": \"text-embedding-ada-002\"\n}\n</code></pre>"},{"location":"configuration/llm/#key-configuration-parameters","title":"Key Configuration Parameters","text":""},{"location":"configuration/llm/#global-settings","title":"Global Settings","text":"Parameter Description Default <code>default_model</code> The default model to use when not specified gpt-4 <code>temperature</code> Global default temperature setting 0.1 <code>max_tokens</code> Global default max tokens setting 4000 <code>request_timeout</code> Timeout for API requests in seconds 60 <code>retry_count</code> Number of retries for failed requests 3 <code>backoff_factor</code> Exponential backoff factor for retries 2"},{"location":"configuration/llm/#model-specific-settings","title":"Model-Specific Settings","text":"<p>Each model can have its own configuration that overrides the global settings:</p> Parameter Description <code>system_message</code> System prompt that defines the model's role and capabilities <code>temperature</code> Controls randomness (0.0-2.0, lower is more deterministic) <code>max_tokens</code> Maximum tokens in the response <code>top_p</code> Nucleus sampling parameter (optional) <code>frequency_penalty</code> Penalty for token frequency (optional) <code>presence_penalty</code> Penalty for token presence (optional)"},{"location":"configuration/llm/#embedding-model","title":"Embedding Model","text":"Parameter Description Default <code>embedding_model</code> Model used for creating vector embeddings text-embedding-ada-002"},{"location":"configuration/llm/#agent-specific-prompts","title":"Agent-Specific Prompts","text":"<p>Different agents use specialized prompts stored in the configuration:</p>"},{"location":"configuration/llm/#formula-resolver-prompts","title":"Formula Resolver Prompts","text":"<pre><code>\"formula_resolver\": {\n  \"system_prompt\": \"You are an expert in energy calculations and formulas...\",\n  \"metric_identification_prompt\": \"Identify the primary energy metric being requested in the following query...\",\n  \"formula_creation_prompt\": \"Create the appropriate formula for calculating {metric}...\"\n}\n</code></pre>"},{"location":"configuration/llm/#qc-auditor-prompts","title":"QC Auditor Prompts","text":"<pre><code>\"qc_auditor\": {\n  \"system_prompt\": \"You are a meticulous quality control expert for energy calculations...\",\n  \"validation_prompt\": \"Validate the following calculation results for accuracy...\"\n}\n</code></pre>"},{"location":"configuration/llm/#environment-variables","title":"Environment Variables","text":"<p>LLM settings can be overridden with environment variables:</p> Variable Description Maps To <code>OPENAI_API_KEY</code> OpenAI API key Required for authentication <code>OPENAI_API_BASE</code> API base URL Used for custom endpoints <code>OPENAI_MODEL</code> Model override <code>default_model</code> <code>OPENAI_TEMPERATURE</code> Temperature override <code>temperature</code> <code>OPENAI_MAX_TOKENS</code> Max tokens override <code>max_tokens</code> <code>OPENAI_EMBEDDING_MODEL</code> Embedding model override <code>embedding_model</code>"},{"location":"configuration/llm/#cost-management","title":"Cost Management","text":"<p>The system includes features to manage API costs:</p> <ul> <li>Caching: Responses are cached to avoid duplicate API calls</li> <li>Batching: Multiple embedding requests are batched</li> <li>Token counting: Preprocessing to estimate token usage</li> <li>Model selection: Automatic downgrading to cheaper models for simpler tasks</li> </ul>"},{"location":"configuration/llm/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"configuration/llm/#model-fallbacks","title":"Model Fallbacks","text":"<p>The system can be configured to fall back to alternative models when the primary model is unavailable:</p> <pre><code>\"fallbacks\": {\n  \"gpt-4\": [\"gpt-4-0613\", \"gpt-3.5-turbo\"],\n  \"gpt-3.5-turbo\": [\"gpt-3.5-turbo-0613\"]\n}\n</code></pre>"},{"location":"configuration/llm/#custom-endpoints","title":"Custom Endpoints","text":"<p>For users running local models or using alternative providers:</p> <pre><code>\"custom_endpoints\": {\n  \"local-llama\": {\n    \"api_base\": \"http://localhost:8000/v1\",\n    \"api_type\": \"open_ai\",\n    \"api_version\": null\n  }\n}\n</code></pre>"},{"location":"configuration/llm/#troubleshooting","title":"Troubleshooting","text":"<p>Common LLM configuration issues and their solutions:</p> Issue Solution API key errors Check <code>OPENAI_API_KEY</code> is set correctly Timeout errors Increase <code>request_timeout</code> value Context length errors Reduce input size or switch to a model with larger context High costs Lower temperature, implement more caching, or use cheaper models"},{"location":"getting-started/","title":"Getting Started","text":"<p>Welcome to the Getting Started guide for the Agentic System. This section will help you understand, install, and begin using the system quickly.</p>"},{"location":"getting-started/#in-this-section","title":"In this section:","text":"<ul> <li>Introduction - Learn about the system's architecture and capabilities</li> <li>Installation - Set up your environment</li> <li>Quickstart - Run your first analysis in 15 minutes</li> </ul>"},{"location":"getting-started/#first-steps","title":"First Steps","text":"<p>If you're new to the Agentic System, we recommend following these steps:</p> <ol> <li>Read the Introduction to understand what the system can do and how it's structured</li> <li>Follow the Installation Guide to set up your environment</li> <li>Complete the Quickstart Tutorial to run your first analysis</li> </ol>"},{"location":"getting-started/#system-requirements","title":"System Requirements","text":"<p>Before installing, ensure your system meets these requirements:</p> <ul> <li>Python: Version 3.11 or higher</li> <li>Memory: At least 4GB RAM (8GB recommended for larger datasets)</li> <li>API Keys: OpenAI API key (and optionally other API keys based on your needs)</li> <li>Operating System: Compatible with Linux, macOS, and Windows</li> </ul>"},{"location":"getting-started/#getting-help","title":"Getting Help","text":"<p>If you encounter any issues during setup or usage:</p> <ul> <li>Check the Troubleshooting Guide</li> <li>Look for specific Installation Issues</li> <li>Review the FAQs for common questions</li> </ul>"},{"location":"getting-started/installation/","title":"Installation Guide","text":"<p>This guide will walk you through the process of setting up the Agentic System environment on your machine.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing the Agentic System, make sure your system meets the following requirements:</p> <ul> <li>Python: Version 3.11 or higher</li> <li>Operating System: Linux, macOS, or Windows</li> <li>Memory: At least 4GB RAM (8GB recommended for larger datasets)</li> <li>Storage: At least 1GB free disk space</li> <li>API Keys: OpenAI API key (and optionally other API keys based on your needs)</li> </ul>"},{"location":"getting-started/installation/#installation-methods","title":"Installation Methods","text":""},{"location":"getting-started/installation/#method-1-using-pip-recommended","title":"Method 1: Using pip (Recommended)","text":"<pre><code># Create a virtual environment\npython -m venv agentic-env\n\n# Activate the virtual environment\n# On Linux/macOS\nsource agentic-env/bin/activate\n# On Windows\nagentic-env\\Scripts\\activate\n\n# Install the package\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/installation/#method-2-from-source","title":"Method 2: From Source","text":"<pre><code># Clone the repository\ngit clone https://github.com/yourusername/agentic-system.git\ncd agentic-system\n\n# Create a virtual environment\npython -m venv venv\n\n# Activate the virtual environment\n# On Linux/macOS\nsource venv/bin/activate\n# On Windows\nvenv\\Scripts\\activate\n\n# Install dependencies\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/installation/#configuration-setup","title":"Configuration Setup","text":"<ol> <li>Create a <code>.env</code> file in the root directory by copying the example:</li> </ol> <pre><code>cp .env.example .env\n</code></pre> <ol> <li>Open the <code>.env</code> file and add your configuration settings:</li> </ol> <pre><code># OpenAI API Configuration\nOPENAI_API_KEY=your_openai_api_key_here\nOPENAI_API_BASE=https://api.openai.com/v1\nOPENAI_MODEL=gpt-4\n\n# Database Configuration\nDATABASE_URL=sqlite:///./data.db\nVECTOR_DB_PATH=./vector_db\n\n# Logging Configuration\nLOG_LEVEL=INFO\n</code></pre> <ol> <li>Create required directories:</li> </ol> <pre><code>mkdir -p logs data/csv data/input_files data/output_files\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>To verify that the installation was successful:</p> <pre><code>python -m main --check-installation\n</code></pre> <p>You should see a message confirming that the system is properly installed and configured.</p>"},{"location":"getting-started/installation/#database-setup-optional","title":"Database Setup (Optional)","text":"<p>If you're using PostgreSQL instead of the default SQLite:</p> <ol> <li>Install PostgreSQL and create a new database</li> <li>Update your <code>.env</code> file with the PostgreSQL connection string:</li> </ol> <pre><code>DATABASE_URL=postgresql://username:password@localhost:5432/agentic_db\n</code></pre> <ol> <li>Run the database initialization script:</li> </ol> <pre><code>python -m scripts.init_db\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues during installation:</p> <ul> <li>Missing dependencies: Make sure you're using Python 3.11+ and have installed all requirements</li> <li>API key errors: Check that your OpenAI API key is valid and correctly set in the <code>.env</code> file</li> <li>Database connection issues: Verify database credentials and that the database server is running</li> </ul> <p>For more detailed troubleshooting guidance, see the Troubleshooting Guide.</p>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Now that you've successfully installed the Agentic System, proceed to the Quickstart Guide to run your first analysis.</p>"},{"location":"getting-started/introduction/","title":"Introduction to Agentic System","text":"<p>The Agentic System is a comprehensive multi-agent framework designed specifically for energy sector analysis, calculations, and reporting. Built with AutoGen and leveraging OpenAI's powerful models, the system specializes in processing complex energy-related queries with precision and flexibility.</p>"},{"location":"getting-started/introduction/#what-is-agentic-system","title":"What is Agentic System?","text":"<p>Agentic System is a modular, multi-agent architecture that processes complex energy analysis queries through specialized agents. Each agent has a specific responsibility and can be called independently or as part of a coordinated workflow.</p> <p>The system excels at:</p> <ul> <li>Processing structured and unstructured data from multiple sources</li> <li>Performing complex calculations with automatic formula resolution</li> <li>Quality control and validation of results</li> <li>Flexible output formatting for various stakeholder needs</li> </ul>"},{"location":"getting-started/introduction/#system-architecture","title":"System Architecture","text":"<p>The system follows a multi-tier architecture:</p> <ol> <li>User Interface Layer: Handles user input and output formatting</li> <li>Task Manager: Central orchestrator that routes queries to appropriate agents</li> <li>Agent Layer: Specialized agents performing specific functions</li> <li>Data Layer: Connects to various data sources and storage systems</li> <li>External Services: Integration with APIs and external systems</li> </ol>"},{"location":"getting-started/introduction/#key-components","title":"Key Components","text":""},{"location":"getting-started/introduction/#core-components","title":"Core Components","text":"<ul> <li>Task Manager: Central orchestrator that routes queries to appropriate agents</li> <li>Base Agent: Abstract base class providing common functionality for all agents</li> <li>Configuration: Centralized settings and environment management</li> </ul>"},{"location":"getting-started/introduction/#specialized-agents","title":"Specialized Agents","text":"<ol> <li>PlexosCSVLoader: Loads and processes Plexos energy modeling CSV files</li> <li>PostgresDataProvider: Connects to external PostgreSQL endpoints for data retrieval</li> <li>DataHarvester: Retrieves data from external sources and APIs</li> <li>RAGIndexer: Builds searchable vector and SQL indices for knowledge retrieval</li> <li>FormulaResolver: Identifies required metrics and retrieves canonical formulas</li> <li>CalcExecutor: Executes numeric computations using Python sandbox</li> <li>QCAuditor: Validates results for accuracy, unit consistency, and citations</li> <li>Exporter: Formats and exports final answers in various formats</li> </ol>"},{"location":"getting-started/introduction/#use-cases","title":"Use Cases","text":"<p>The Agentic System is designed to tackle a wide range of energy sector analytical challenges:</p> <ul> <li>Energy Cost Analysis: Calculating LCOE, NPV, and IRR for energy projects</li> <li>Data-Driven Decision Making: Processing complex datasets for insights</li> <li>Scenario Planning: Modeling different energy scenarios with variable inputs</li> <li>Quality Assurance: Validating calculations and ensuring accuracy</li> <li>Report Generation: Creating standardized or custom reports from analyses</li> </ul>"},{"location":"getting-started/introduction/#next-steps","title":"Next Steps","text":"<p>To get started with the Agentic System:</p> <ol> <li>Follow the Installation Guide to set up your environment</li> <li>Complete the Quickstart Tutorial to run your first analysis</li> <li>Explore the Configuration Options to customize the system</li> </ol>"},{"location":"getting-started/quickstart/","title":"Quickstart Guide","text":"<p>This guide will help you get up and running with the Agentic System in just a few minutes. By the end, you'll be able to process your first energy analysis query.</p>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have:</p> <ul> <li>Completed the installation process</li> <li>Activated your Python virtual environment</li> <li>Set up your <code>.env</code> file with the required API keys</li> </ul>"},{"location":"getting-started/quickstart/#your-first-analysis","title":"Your First Analysis","text":""},{"location":"getting-started/quickstart/#step-1-import-the-system","title":"Step 1: Import the System","text":"<p>Create a new Python file called <code>first_analysis.py</code> and add the following code:</p> <pre><code>import asyncio\nfrom main import AgenticSystem\n\nasync def run_analysis():\n    # Initialize the system\n    system = AgenticSystem()\n\n    # Process a simple query\n    result = await system.process_query(\n        \"Calculate the LCOE for a solar project with CAPEX of $1000/kW, \"\n        \"OPEX of $20/kW/year, capacity factor of 25%, and 25-year lifetime \"\n        \"with 7% discount rate\"\n    )\n\n    print(\"Analysis Results:\")\n    print(result)\n\n# Run the analysis\nif __name__ == \"__main__\":\n    asyncio.run(run_analysis())\n</code></pre>"},{"location":"getting-started/quickstart/#step-2-run-the-analysis","title":"Step 2: Run the Analysis","text":"<p>Execute the script from your terminal:</p> <pre><code>python first_analysis.py\n</code></pre> <p>The system will: 1. Parse the query to understand what calculation is required 2. Identify the necessary formula (LCOE in this case) 3. Extract parameters from the query 4. Perform the calculation 5. Validate the results 6. Return a structured response</p>"},{"location":"getting-started/quickstart/#step-3-customize-the-query","title":"Step 3: Customize the Query","text":"<p>Try modifying the query to explore different calculations:</p> <pre><code># For Net Present Value (NPV) calculation\nresult = await system.process_query(\n    \"Calculate the NPV for a wind project with initial investment of $5M, \"\n    \"annual revenue of $800K, annual costs of $200K, 20-year lifetime, \"\n    \"and 8% discount rate\"\n)\n\n# For Capacity Factor analysis\nresult = await system.process_query(\n    \"What is the average capacity factor for onshore wind farms in Texas \"\n    \"based on the most recent available data?\"\n)\n</code></pre>"},{"location":"getting-started/quickstart/#using-direct-agent-calls","title":"Using Direct Agent Calls","text":"<p>For more specific needs, you can call agents directly:</p> <pre><code># Call the CalcExecutor agent directly\ncalc_result = await system.direct_agent_call(\"CalcExecutor\", {\n    \"formula\": \"CAPEX / (capacity_factor * 8760 * lifetime * (1 - (1 / ((1 + discount_rate) ** lifetime))))\",\n    \"parameters\": {\n        \"CAPEX\": 1000,  # $/kW\n        \"capacity_factor\": 0.25,\n        \"lifetime\": 25,  # years\n        \"discount_rate\": 0.07\n    }\n})\n\nprint(\"Direct calculation result:\", calc_result[\"data\"][\"result\"])\n</code></pre>"},{"location":"getting-started/quickstart/#working-with-data-files","title":"Working with Data Files","text":"<p>To analyze data from CSV files:</p> <pre><code># Load and analyze CSV data\nresult = await system.process_query(\n    \"Analyze the capacity factors in data/csv/example_plant_data.csv \"\n    \"and calculate the average monthly values for 2022\"\n)\n</code></pre>"},{"location":"getting-started/quickstart/#whats-next","title":"What's Next?","text":"<p>Now that you've completed your first analysis, explore these features:</p> <ul> <li>Advanced Calculations: Try more complex formulas and scenarios</li> <li>Data Integration: Connect to external databases or APIs</li> <li>Custom Exports: Generate reports in different formats</li> <li>Configuration: Customize the system for your specific needs</li> </ul> <p>For detailed documentation on these topics, refer to:</p> <ul> <li>Advanced Features</li> <li>Configuration Options</li> <li>API Reference</li> </ul> <p>Happy analyzing!</p>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>This guide helps you diagnose and resolve common issues with the Agentic System.</p>"},{"location":"troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"troubleshooting/#api-key-configuration","title":"API Key Configuration","text":"<p>Problem: System fails with authentication errors <pre><code>OpenAIError: Authentication failed. Please check your API key.\n</code></pre></p> <p>Solution: 1. Verify your API key is correctly set in the <code>.env</code> file 2. Check for extra whitespace around the key 3. Ensure the API key is active in your OpenAI account 4. Try exporting the key directly in your terminal:    <pre><code>export OPENAI_API_KEY=your-key-here\n</code></pre></p>"},{"location":"troubleshooting/#python-version-incompatibility","title":"Python Version Incompatibility","text":"<p>Problem: Installation fails with package compatibility errors <pre><code>ERROR: Package requires Python&gt;=3.11 but you have Python 3.9.5\n</code></pre></p> <p>Solution: 1. Check your Python version: <code>python --version</code> 2. Install Python 3.11 or higher 3. Create a new virtual environment with the correct Python version:    <pre><code>python3.11 -m venv venv\nsource venv/bin/activate\n</code></pre></p>"},{"location":"troubleshooting/#missing-dependencies","title":"Missing Dependencies","text":"<p>Problem: Import errors when running the system <pre><code>ImportError: No module named 'chromadb'\n</code></pre></p> <p>Solution: 1. Ensure you've installed all dependencies: <code>pip install -r requirements.txt</code> 2. Check for any OS-specific dependencies that might need separate installation 3. If using a virtual environment, verify it's activated 4. For specific package errors, try installing individually: <code>pip install chromadb</code></p>"},{"location":"troubleshooting/#configuration-issues","title":"Configuration Issues","text":""},{"location":"troubleshooting/#missing-configuration-files","title":"Missing Configuration Files","text":"<p>Problem: System cannot find configuration files <pre><code>FileNotFoundError: [Errno 2] No such file or directory: '.../config/llm_settings.json'\n</code></pre></p> <p>Solution: 1. Verify all configuration files exist in the <code>config/</code> directory 2. Create missing files based on example templates 3. Check file permissions 4. Ensure paths are correct for your OS</p>"},{"location":"troubleshooting/#database-connection-errors","title":"Database Connection Errors","text":"<p>Problem: Unable to connect to PostgreSQL database <pre><code>psycopg2.OperationalError: could not connect to server: Connection refused\n</code></pre></p> <p>Solution: 1. Verify database server is running 2. Check connection settings in <code>config/postgres_settings.json</code> 3. Ensure the database exists and user has appropriate permissions 4. Try connecting with a direct client like <code>psql</code> to verify credentials 5. Check for firewall or network restrictions</p>"},{"location":"troubleshooting/#runtime-issues","title":"Runtime Issues","text":""},{"location":"troubleshooting/#llm-timeouts","title":"LLM Timeouts","text":"<p>Problem: LLM API calls time out <pre><code>TimeoutError: OpenAI API request timed out: (read timeout=60)\n</code></pre></p> <p>Solution: 1. Increase the timeout setting in configuration 2. Check your internet connection 3. Verify the OpenAI service status 4. Consider reducing token length in requests 5. Implement retry logic for intermittent failures</p>"},{"location":"troubleshooting/#memory-issues","title":"Memory Issues","text":"<p>Problem: System crashes with memory errors <pre><code>MemoryError: Unable to allocate array with shape (50000, 1536)\n</code></pre></p> <p>Solution: 1. Reduce batch sizes for embedding operations 2. Process large datasets in smaller chunks 3. Increase system memory or use swap space 4. Close unused applications to free memory 5. Consider cloud deployment for memory-intensive operations</p>"},{"location":"troubleshooting/#calculation-errors","title":"Calculation Errors","text":"<p>Problem: Numerical errors in calculations <pre><code>ValueError: Math domain error in calculation\n</code></pre></p> <p>Solution: 1. Check input parameters for invalid values (negative values, zeros) 2. Verify formulas in the FormulaResolver 3. Add validation for edge cases 4. Implement proper error handling for mathematical operations 5. Use the QCAuditor agent to validate results</p>"},{"location":"troubleshooting/#agent-specific-issues","title":"Agent-Specific Issues","text":""},{"location":"troubleshooting/#plexoscsvloader-issues","title":"PlexosCSVLoader Issues","text":"<p>Problem: Cannot parse CSV files <pre><code>Error: Unable to parse CSV file: Unexpected delimiter found\n</code></pre></p> <p>Solution: 1. Check CSV file format and encoding 2. Verify delimiter settings match the file format 3. Inspect the file for corruption or special characters 4. Try preprocessing the file with standard tools like <code>pandas</code></p>"},{"location":"troubleshooting/#postgresdataprovider-issues","title":"PostgresDataProvider Issues","text":"<p>Problem: Self-healing queries fail to find data <pre><code>Error: Failed to retrieve data after multiple fallback attempts\n</code></pre></p> <p>Solution: 1. Check the data actually exists in the database 2. Increase <code>max_fallback_attempts</code> in configuration 3. Examine self-healing metadata for specific failure points 4. Add more relaxation strategies 5. Verify database indexes for performance</p>"},{"location":"troubleshooting/#ragindexer-issues","title":"RAGIndexer Issues","text":"<p>Problem: Vector search returns irrelevant results <pre><code>Warning: Vector search similarity scores below threshold\n</code></pre></p> <p>Solution: 1. Rebuild the vector index with updated embeddings 2. Check embedding model configuration 3. Verify document preprocessing steps 4. Adjust similarity thresholds 5. Consider hybrid search with keyword filtering</p>"},{"location":"troubleshooting/#logging-and-debugging","title":"Logging and Debugging","text":""},{"location":"troubleshooting/#enabling-debug-logs","title":"Enabling Debug Logs","text":"<p>To get more detailed logs for troubleshooting:</p> <ol> <li> <p>Set the log level in your <code>.env</code> file:    <pre><code>LOG_LEVEL=DEBUG\n</code></pre></p> </li> <li> <p>Check the logs directory for detailed output:    <pre><code>tail -f logs/agentic_system.log\n</code></pre></p> </li> <li> <p>Filter logs for specific components:    <pre><code>grep \"PostgresDataProvider\" logs/agentic_system.log\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#common-log-patterns","title":"Common Log Patterns","text":"<p>Look for these patterns in logs to identify issues:</p> <ul> <li><code>ERROR</code> messages indicate critical failures</li> <li><code>WARNING</code> messages suggest potential issues that didn't cause failure</li> <li>Messages with <code>retry attempt #</code> indicate API retries</li> <li>Timing information with <code>processing_time_ms</code> helps identify performance bottlenecks</li> </ul>"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you continue to experience issues:</p> <ol> <li>Check the GitHub repository issues section</li> <li>Search for similar problems in the documentation</li> <li>Run the system diagnostics:    <pre><code>python -m diagnostics.system_check\n</code></pre></li> <li>Collect relevant logs and configuration for support requests</li> <li>Provide a minimal reproducible example when asking for help</li> </ol>"},{"location":"troubleshooting/faqs/","title":"FAQs","text":""},{"location":"troubleshooting/faqs/#general-questions","title":"General Questions","text":""},{"location":"troubleshooting/faqs/#what-is-the-agentic-system","title":"What is the Agentic System?","text":"<p>The Agentic System is a comprehensive multi-agent framework designed specifically for energy sector analysis, calculations, and reporting. It uses specialized agents to process complex queries, retrieve data, perform calculations, and generate reports.</p>"},{"location":"troubleshooting/faqs/#what-can-i-use-the-agentic-system-for","title":"What can I use the Agentic System for?","text":"<p>The system excels at: - Energy calculations (LCOE, NPV, IRR, etc.) - Data analysis and processing - Formula resolution and validation - Quality control and reporting - Multi-format exports</p>"},{"location":"troubleshooting/faqs/#is-the-system-open-source","title":"Is the system open source?","text":"<p>Yes, the Agentic System is open source and available under the MIT license. You can use, modify, and distribute it according to the terms of this license.</p>"},{"location":"troubleshooting/faqs/#technical-questions","title":"Technical Questions","text":""},{"location":"troubleshooting/faqs/#which-python-versions-are-supported","title":"Which Python versions are supported?","text":"<p>The Agentic System requires Python 3.11 or higher. This requirement exists due to our use of newer language features and dependencies that require this version.</p>"},{"location":"troubleshooting/faqs/#can-i-use-a-different-llm-provider-than-openai","title":"Can I use a different LLM provider than OpenAI?","text":"<p>The system is designed with OpenAI's models as the default, but it can be configured to work with other providers that implement a compatible API. Check the LLM Configuration document for details.</p>"},{"location":"troubleshooting/faqs/#how-do-i-contribute-to-the-project","title":"How do I contribute to the project?","text":"<p>Contributions are welcome! Please check our GitHub repository for contribution guidelines. Typical ways to contribute include submitting bug reports, feature requests, documentation improvements, and code contributions through pull requests.</p>"},{"location":"troubleshooting/faqs/#installation-questions","title":"Installation Questions","text":""},{"location":"troubleshooting/faqs/#im-getting-a-no-module-named-openai-error-how-do-i-fix-it","title":"I'm getting a \"No module named 'openai'\" error, how do I fix it?","text":"<p>This usually means the OpenAI Python library wasn't properly installed. Try installing it manually:</p> <pre><code>pip install openai\n</code></pre>"},{"location":"troubleshooting/faqs/#do-i-need-a-gpu-to-run-the-system","title":"Do I need a GPU to run the system?","text":"<p>No, a GPU is not required as the system uses cloud-based LLMs by default. However, if you configure it to use local models, a GPU might significantly improve performance.</p>"},{"location":"troubleshooting/faqs/#can-i-run-the-system-in-docker","title":"Can I run the system in Docker?","text":"<p>Yes, we provide Docker configurations. See the Docker setup instructions in the Installation Guide.</p>"},{"location":"troubleshooting/faqs/#usage-questions","title":"Usage Questions","text":""},{"location":"troubleshooting/faqs/#how-do-i-customize-the-system-for-my-specific-needs","title":"How do I customize the system for my specific needs?","text":"<p>The system is highly configurable through: - Configuration files in the <code>config/</code> directory - Environment variables - Direct code customization</p> <p>See the Configuration section for details.</p>"},{"location":"troubleshooting/faqs/#can-the-system-handle-large-datasets","title":"Can the system handle large datasets?","text":"<p>Yes, but with some considerations: - Large datasets may require more memory - Processing time will increase with data size - Consider using chunked processing for very large datasets - Vector databases have size limits to consider</p>"},{"location":"troubleshooting/faqs/#how-accurate-are-the-calculations","title":"How accurate are the calculations?","text":"<p>The system includes: - Precise formula implementation - Quality control validation - Unit consistency checks - Range validation</p> <p>However, results are only as accurate as the input data and formulas provided. Always validate critical calculations using multiple methods.</p>"},{"location":"troubleshooting/faqs/#troubleshooting-questions","title":"Troubleshooting Questions","text":""},{"location":"troubleshooting/faqs/#why-is-the-system-timing-out-on-large-calculations","title":"Why is the system timing out on large calculations?","text":"<p>Try: 1. Increasing the timeout settings in the configuration 2. Breaking large calculations into smaller parts 3. Optimizing the query to reduce data volume 4. Increasing system resources (memory/CPU)</p>"},{"location":"troubleshooting/faqs/#how-do-i-debug-agent-failures","title":"How do I debug agent failures?","text":"<ol> <li>Check the logs in the <code>logs/</code> directory</li> <li>Set the log level to DEBUG in your configuration</li> <li>Try calling the specific agent directly with simpler inputs</li> <li>Check the error details in the response</li> </ol>"},{"location":"troubleshooting/faqs/#why-isnt-my-postgresql-connection-working","title":"Why isn't my PostgreSQL connection working?","text":"<p>Common issues include: - Incorrect credentials in the configuration - Database server not running - Network/firewall issues - Missing database or tables - Insufficient permissions</p> <p>See the Database Configuration document for troubleshooting steps.</p>"},{"location":"troubleshooting/installation_issues/","title":"Installation Issues","text":"<p>This page addresses common installation problems and their solutions.</p>"},{"location":"troubleshooting/installation_issues/#environment-setup-issues","title":"Environment Setup Issues","text":""},{"location":"troubleshooting/installation_issues/#python-version-problems","title":"Python Version Problems","text":"<p>Problem: System requires Python 3.11+ but you have an older version</p> <p>Symptoms: <pre><code>ERROR: Package requires Python&gt;=3.11 but you have Python 3.x.x\n</code></pre></p> <p>Solutions:</p>"},{"location":"troubleshooting/installation_issues/#for-macos","title":"For macOS:","text":"<pre><code># Using Homebrew\nbrew update\nbrew install python@3.11\n\n# Make it the default Python\necho 'alias python=\"/usr/local/bin/python3.11\"' &gt;&gt; ~/.zshrc\nsource ~/.zshrc\n</code></pre>"},{"location":"troubleshooting/installation_issues/#for-linux","title":"For Linux:","text":"<pre><code># For Ubuntu/Debian\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt update\nsudo apt install python3.11 python3.11-venv python3.11-dev\n\n# Make it the default Python\necho 'alias python=\"python3.11\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>"},{"location":"troubleshooting/installation_issues/#for-windows","title":"For Windows:","text":"<ol> <li>Download Python 3.11 installer from python.org</li> <li>Run installer with \"Add Python to PATH\" checked</li> <li>Open a new command prompt to use the updated Python</li> </ol>"},{"location":"troubleshooting/installation_issues/#virtual-environment-issues","title":"Virtual Environment Issues","text":"<p>Problem: Errors creating or activating virtual environment</p> <p>Symptoms: <pre><code>Error: Command '['python', '-m', 'venv', 'venv']' returned non-zero exit status 1.\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Install venv package if missing:    <pre><code># For Ubuntu/Debian\nsudo apt install python3.11-venv\n\n# For macOS\npip3 install virtualenv\n</code></pre></p> </li> <li> <p>Use virtualenv as an alternative:    <pre><code>pip install virtualenv\nvirtualenv venv\n</code></pre></p> </li> <li> <p>Check file permissions:    <pre><code># Fix permissions on directory\nchmod 755 .\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/installation_issues/#dependency-installation-issues","title":"Dependency Installation Issues","text":""},{"location":"troubleshooting/installation_issues/#package-installation-failures","title":"Package Installation Failures","text":"<p>Problem: Installing requirements.txt fails</p> <p>Symptoms: <pre><code>ERROR: Failed building wheel for llvmlite\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Install system dependencies:    <pre><code># For Ubuntu/Debian\nsudo apt-get install build-essential libffi-dev python-dev\n\n# For macOS\nbrew install llvm\n</code></pre></p> </li> <li> <p>Update pip and setuptools:    <pre><code>pip install --upgrade pip setuptools wheel\n</code></pre></p> </li> <li> <p>Install packages one by one to identify problematic ones:    <pre><code>while read requirement; do pip install $requirement; done &lt; requirements.txt\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/installation_issues/#ssl-certificate-errors","title":"SSL Certificate Errors","text":"<p>Problem: SSL certificate verification fails during package download</p> <p>Symptoms: <pre><code>Could not fetch URL: There was a problem confirming the ssl certificate\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Update certificates:    <pre><code># For macOS\n/Applications/Python\\ 3.11/Install\\ Certificates.command\n\n# For Linux\nsudo apt-get install ca-certificates\n</code></pre></p> </li> <li> <p>Temporarily bypass (not recommended for production):    <pre><code>pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org -r requirements.txt\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/installation_issues/#api-key-configuration","title":"API Key Configuration","text":""},{"location":"troubleshooting/installation_issues/#openai-api-key-issues","title":"OpenAI API Key Issues","text":"<p>Problem: System can't find or authenticate with OpenAI API key</p> <p>Symptoms: <pre><code>openai.error.AuthenticationError: Incorrect API key provided\n</code></pre></p> <p>Solutions:</p> <ol> <li>Verify key format - should be <code>sk-...</code> without extra spaces</li> <li> <p>Set environment variable directly:    <pre><code># For Linux/macOS\nexport OPENAI_API_KEY=\"sk-...\"\n\n# For Windows (Command Prompt)\nset OPENAI_API_KEY=sk-...\n\n# For Windows (PowerShell)\n$env:OPENAI_API_KEY=\"sk-...\"\n</code></pre></p> </li> <li> <p>Check API key status in OpenAI dashboard</p> </li> <li>Create a new API key if necessary</li> </ol>"},{"location":"troubleshooting/installation_issues/#env-file-issues","title":".env File Issues","text":"<p>Problem: System not reading .env file correctly</p> <p>Symptoms: <pre><code>KeyError: 'OPENAI_API_KEY'\n</code></pre></p> <p>Solutions:</p> <ol> <li>Verify .env file location (must be in project root)</li> <li> <p>Check .env file format:    <pre><code>OPENAI_API_KEY=sk-...\n</code></pre>    No quotes needed, no spaces around <code>=</code></p> </li> <li> <p>Install python-dotenv if missing:    <pre><code>pip install python-dotenv\n</code></pre></p> </li> <li> <p>Explicitly load .env file in your code:    <pre><code>from dotenv import load_dotenv\nload_dotenv(verbose=True)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/installation_issues/#database-setup-issues","title":"Database Setup Issues","text":""},{"location":"troubleshooting/installation_issues/#postgresql-installation-problems","title":"PostgreSQL Installation Problems","text":"<p>Problem: PostgreSQL installation or connection fails</p> <p>Symptoms: <pre><code>psycopg2.OperationalError: could not connect to server\n</code></pre></p> <p>Solutions:</p>"},{"location":"troubleshooting/installation_issues/#for-macos_1","title":"For macOS:","text":"<pre><code># Install PostgreSQL with Homebrew\nbrew install postgresql\nbrew services start postgresql\n\n# Create required database\ncreatedb energy_data\n</code></pre>"},{"location":"troubleshooting/installation_issues/#for-linux_1","title":"For Linux:","text":"<pre><code># For Ubuntu/Debian\nsudo apt install postgresql postgresql-contrib\nsudo systemctl start postgresql\nsudo systemctl enable postgresql\n\n# Create required database\nsudo -u postgres createdb energy_data\n</code></pre>"},{"location":"troubleshooting/installation_issues/#for-docker","title":"For Docker:","text":"<pre><code># Use Docker Compose\ndocker-compose up -d postgres\n</code></pre>"},{"location":"troubleshooting/installation_issues/#postgresql-connection-issues","title":"PostgreSQL Connection Issues","text":"<p>Problem: System can't connect to PostgreSQL database</p> <p>Solutions:</p> <ol> <li>Check connection parameters in <code>config/postgres_settings.json</code></li> <li> <p>Verify PostgreSQL is running:    <pre><code># For macOS/Linux\npg_isready\n\n# Check status on systemd systems\nsudo systemctl status postgresql\n</code></pre></p> </li> <li> <p>Test connection with psql:    <pre><code>psql -h localhost -U postgres -d energy_data\n</code></pre></p> </li> <li> <p>Check firewall settings if connecting remotely</p> </li> </ol>"},{"location":"troubleshooting/installation_issues/#system-specific-issues","title":"System-Specific Issues","text":""},{"location":"troubleshooting/installation_issues/#macos-specific-problems","title":"macOS Specific Problems","text":"<p>Problem: Missing compiler tools on macOS</p> <p>Symptoms: <pre><code>xcrun: error: invalid active developer path\n</code></pre></p> <p>Solution: <pre><code>xcode-select --install\n</code></pre></p>"},{"location":"troubleshooting/installation_issues/#linux-specific-problems","title":"Linux Specific Problems","text":"<p>Problem: Missing system libraries</p> <p>Symptoms: <pre><code>ImportError: libGL.so.1: cannot open shared object file\n</code></pre></p> <p>Solution: <pre><code>sudo apt-get update\nsudo apt-get install -y \\\n    libgl1-mesa-glx \\\n    libglib2.0-0\n</code></pre></p>"},{"location":"troubleshooting/installation_issues/#windows-specific-problems","title":"Windows Specific Problems","text":"<p>Problem: Path length limitations</p> <p>Symptoms: <pre><code>ERROR: Could not install packages due to an OSError: [WinError 206]\n</code></pre></p> <p>Solution: 1. Enable long paths in Windows:    - Run regedit    - Navigate to <code>HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem</code>    - Set <code>LongPathsEnabled</code> to <code>1</code>    - Restart computer</p> <ol> <li>Use shorter installation directory</li> </ol>"},{"location":"troubleshooting/installation_issues/#next-steps","title":"Next Steps","text":"<p>If you've resolved your installation issues:</p> <ul> <li>Proceed to the Quickstart Guide</li> <li>Verify installation with system diagnostics:   <pre><code>python -m main --check-installation\n</code></pre></li> <li>Run the test suite to ensure everything is working:   <pre><code>python -m pytest tests/\n</code></pre></li> </ul> <p>If you're still experiencing issues:</p> <ul> <li>Check the GitHub repository for similar issues</li> <li>Post a detailed description of your problem including:</li> <li>Your operating system and version</li> <li>Python version</li> <li>Full error message</li> <li>Steps to reproduce</li> </ul>"}]}